{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==============================================================================\n",
    "### SCRIPT NAME: 03_CS_Modeling\n",
    "### PURPOSE: Develop model\n",
    "### PACKAGES NEEDED: numpy, pandas, matplotlib, seaborn, sklearn\n",
    "### =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will be introduced to DATA MODELING in Python.\n",
    "\n",
    "Whenever in doubt you can always refer to these resources:\n",
    "\n",
    "    help([function name]): Provides a detailed description of the function/\n",
    "    online pandas documentation: https://pandas.pydata.org/pandas-docs/stable/?v=20200107131408\n",
    "    online matplotlib documentation: https://matplotlib.org/contents.html?v=20200131112331\n",
    "    online seaborn documentation: https://seaborn.pydata.org/\n",
    "\n",
    "Note that whenever you see multiple consecutive question marks (like '???') you will have to enter something. Evaluating a cell can be done by clicking on the 'run' button at the top or by pressing shift + enter on a selected cell.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Links to the Exercises\n",
    "\n",
    "[Exercise 1 : Linear Regression](#exercise1)  \n",
    "[Exercise 2 : Logistic Regression](#exercise2)  \n",
    "[Exercise 3 : Decision Trees](#exercise3)  \n",
    "[Exercise 4 : Random Forest](#exercise4)  \n",
    "[Exercise 5 : K-Means Clustering](#exercise5)   \n",
    "[Bonus      : Selecting Variables based on Importance](#bonus) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required packages #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages\n",
    "    import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge\n",
    "from sklearn.tree import export_graphviz, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor#, partial_dependence\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import auc, roc_curve, precision_recall_curve\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# for tree visualization\n",
    "from io import StringIO # make sure this is installed?\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset Model_data.csv and check first rows\n",
    "\n",
    "    pd.read_csv: Loads csv file\n",
    "    DataFrame.head(): Shows first n rows of the table (default: 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/cleaned_dataset.csv')\n",
    "print(data.shape)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For our modeling, we only want some of the columns\n",
    "\n",
    "The right columns have been decided with the process expert and the data scientist. This can however also be a guess in the beginning, and be updated when we start testing some models.\n",
    "\n",
    "Let's use the following 6 columns as inputs:\n",
    "\n",
    "    'glass_temp_zone1',\n",
    "    'glass_temp_zone4',\n",
    "    'temp_chamber17',\n",
    "    'pressing_pressure',\n",
    "    'pressing_time',\n",
    "    'cycle_time',\n",
    "    \n",
    "And the target variable (the one we want to predict):\n",
    "\n",
    "    'geometry_final'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only a couple of variables\n",
    "variables = [\n",
    "    'glass_temp_zone1',\n",
    "    'glass_temp_zone4',\n",
    "    'temp_chamber17',\n",
    "    'pressing_pressure',\n",
    "    'pressing_time',\n",
    "    'cycle_time',\n",
    "    'geometry_final',\n",
    "    ]\n",
    "\n",
    "# data_model = data[variables].copy()\n",
    "data_model = data[?????].copy()\n",
    "\n",
    "data_model = data_model.dropna()\n",
    "\n",
    "data_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='exercise1'>Exercise 1 - Linear Regression</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will use a __linear regression__ model to see if we can predict 'geometry_final' from the predictor variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As always, let's look at the data using describe()\n",
    "data_model.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into train and test data sets\n",
    "    model_selection.train_test_split(): Returns 4 tables:\n",
    "        X_train: modeling set for training\n",
    "        Y_train: target set for training\n",
    "        X_test: modeling set for testing\n",
    "        Y_test: target set for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    data_model.drop('geometry_final', axis=1),  # data set excl. target function\n",
    "    data_model['geometry_final'],               # target function\n",
    "    test_size=0.2,                                # ratio of train and test sets\n",
    "    random_state=123                              # setting up root for random split of data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look into X_train, X_test, Y_train and Y_test:\n",
    "\n",
    "    DataFrame.head()\n",
    "    DataFrame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data of the train and test sets\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the linear regression object and train it\n",
    "    LinearRegression(): Defines model to be used, in this case: LinearRegression from linear_model class\n",
    "    fit(): Trains defined model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression()       # Create the lR model called regr\n",
    "regr.fit(X_train, Y_train);     # Train the model on the train datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The coefficients and intercept\n",
    "    coef_: Lists coefficients of the linear regression model\n",
    "    intercept_: Lists intercept of the linear regression model\n",
    "    \n",
    "Reminder: if we want to show more than 1 output per Jupyter cell, we need to use print() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficients: \\n', regr.coef_)\n",
    "print('Intercept: \\n', regr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions using the testing set\n",
    "    predict(): Applies trained model to new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = regr.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model\n",
    "    mean_squared_error(actual value, predicted value)   : Calculates MSE between actual and predicted value\n",
    "    r2_score(actual value, predicted value)             : Calculates R2 between actual and predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"METRICS FOR LINEAR REGRESSION\")\n",
    "print('Test Set Mean Squared Error : ', mean_squared_error(Y_test, pred))\n",
    "print('Test Set R2                 : ', r2_score(Y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare performance to a benchmark (default) model\n",
    "\n",
    "To better appreciate if this performance is good or not, and if the model has learnt from the input variables, a good strategy is to compare it to a benchmark model that does not uses input variables.\n",
    "\n",
    "    DummyRegressor(): defines an extremely simple model that does not use inputs. Default strategy is to always predicts the mean of the training set. This model behaves the same way as any other scikit-learn model, with functions .fit() and .predict()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the benchmark model\n",
    "dummy = DummyRegressor()\n",
    "\n",
    "# train the model with input and output variables from the train set\n",
    "dummy.fit(X_train, Y_train)\n",
    "\n",
    "# compute predictions for the test set\n",
    "Y_dummy = dummy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"METRICS FOR DUMMY REGRESSION\")\n",
    "print('Test Set Mean Squared Error : ', mean_squared_error(Y_test, Y_dummy))\n",
    "print('Test Set R2                 : ', r2_score(Y_test, Y_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that this can be equivalently done by:\n",
    "np.mean((Y_test-np.mean(Y_train))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = mean_squared_error(Y_test, Y_dummy)\n",
    "MSE = mean_squared_error(Y_test, pred)\n",
    "\n",
    "print(\"The MSE has dropped by\", 100*(benchmark-MSE)/benchmark, \"% thanks to the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=Y_test, y=pred, label='Predictions')\n",
    "sns.lineplot(x=Y_test, y=Y_test, color='gray', label='Perfect model')\n",
    "\n",
    "plt.axis('equal') # Make both axes scaled equally\n",
    "plt.xlabel('Real geometry_final [mm]')\n",
    "plt.ylabel('Predicted geometry_final [mm]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Plot residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using MatPlotLib\n",
    "sns.scatterplot(x=pred, y=(Y_test - pred), label='Predictions')\n",
    "plt.axhline(0, color='gray', label='Perfect model') # adds reference line y = 0\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Rediduals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='exercise2'>Exercise 2 - Logistic Regression</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define new target variable\n",
    "The quality control department has established that a produced piece is *good* if the target variable 'geometry_final' is above between -1.0 and 1.0. We will now try to predict if a piece is good from input variables, using classification models.\n",
    "\n",
    "Let's define a new variable 'geometry_ok' which is 1 when the product is good (-1.0 > 'geometry_final' > 1.0) and 0 when the product is not good.\n",
    "\n",
    "We'll start by looking at a line graph of 'geometry_final'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a line plot of 'geometry_final' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model['geometry_final'].plot()\n",
    "\n",
    "# Plot lines where we're thinking about putting limits\n",
    "plt.axhline(y=1.0, ls='--');\n",
    "plt.axhline(y=-1.0, ls='--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the new variable 'geometry_ok'\n",
    "New variable is equal 1 if 'Rolling_force_avg' is above the threshold value 1.75, otherwise it is 0.\n",
    "A recommended method to assign a value to a column only for a selection of rows is to use the .loc command:\n",
    "\n",
    "    data.loc[condition, 'variable_to_assign'] =  value_to_assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we define a new column with value 0 for all rows\n",
    "data_model['geometry_ok'] = 0\n",
    "\n",
    "# then we assign the value 1 only on rows where 'geometry_final' is between -1.0 and 1.0\n",
    "data_model.loc[(data_model['geometry_final'].between(-1, 1)), 'geometry_ok'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that this is correct\n",
    "data_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count values of 'Target' variable\n",
    "    DataFrame['variable'].value_counts(): Count number of rows per level of variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much of the data is in the desired range (1) and outside the desired range (0)\n",
    "data_model['geometry_ok'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split train and test\n",
    "    train_test_split(): Returns 4 tables (modeling and target for train and test sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    data_model.drop(['geometry_final', 'geometry_ok'], axis=1), # data set excl. target function\n",
    "    data_model['geometry_ok'],                                     # target function\n",
    "    test_size=0.2,                                          # ratio of train and test sets\n",
    "    random_state=0                                           # setting up root for random split of data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the logistic regression object and train it\n",
    "    LogisticRegression(): Defines model to be used, in this case: Logistic regression from linear_model class\n",
    "    fit(): Trains defined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = LogisticRegression()\n",
    "glm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions using the testing set\n",
    "    predict(): Applies trained model to new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the 'Target' using the test set\n",
    "target_pred = glm.predict(X_test)\n",
    "target_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with the real value\n",
    "np.array(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The coefficients and intercept\n",
    "    coef_\n",
    "    intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficients: \\n', glm.coef_)\n",
    "print('Intercepts: \\n', glm.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate using the Confusion Matrix\n",
    "    confusion_matrix(actual, predicted)  : Calculates confussion matrix for test actual and predicted values\n",
    "    accuracy_score(actual, predicted)    : Calculates accuracy of the model (ratio of good answers)\n",
    "    \n",
    "    Learn more here : https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The confusion matrix and metrics are classes we imported from SKLearn at the start \n",
    "print('Confusion matrix: \\n', confusion_matrix(Y_test,target_pred))\n",
    "print('Accuracy: ', accuracy_score(Y_test, target_pred))\n",
    "\n",
    "conf_mat = confusion_matrix(Y_test,target_pred)\n",
    "\n",
    "df_cm = pd.DataFrame(conf_mat, index=['Real not OK','Real OK'], columns=['Predicted not OK', 'Predicted OK'])\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt='d', cbar=False) # font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: threshold, precision/recall tuning, ROC and AUC\n",
    "\n",
    "Play with the value of the probability threshold (default value: 0.5) to see the effect on recall and precision scores. \n",
    "\n",
    "- **accuracy**:  ratio of good answers (global) (TP+TN)/(TP+TN+FP+FN)\n",
    "- **precision**: ratio of good answers among predictions of good products TP/(TP+FP)\n",
    "- **recall**:    ratio of good answers among good products TP/(TP+FN)\n",
    "- **F1 score**:  harmonic mean of precision and recall, decreases as soon as one of them decreases\n",
    "\n",
    "If the priority is to avoid False Positives (selling an undetected bad product could be very dangerous), **precision** must be high.\n",
    "\n",
    "If the priority is to avoid False Negatives (predictive maintenance where extra checks are not an issue but missing one is), **recall** must be high.\n",
    "\n",
    "If both are important (quality control with high cost of production), **F1 score** must be high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = LogisticRegression()\n",
    "glm.fit(X_train, Y_train)\n",
    "\n",
    "# default value for the threshold is 0.5\n",
    "# try with different values in [0, 1] to see the effect\n",
    "threshold = 0.4\n",
    "\n",
    "# prediction is replaced by a two-steps process\n",
    "target_probas = glm.predict_proba(X_test)\n",
    "target_pred = (target_probas[:,1]>=threshold).astype(int)\n",
    "\n",
    "# compute and show the different metrics\n",
    "print('Confusion matrix: \\n', confusion_matrix(Y_test,target_pred))\n",
    "print(\"Accuracy score:   {:.3f}\".format(accuracy_score(Y_test, target_pred)))\n",
    "print(\"Recall score:     {:.3f}\".format(recall_score(Y_test,target_pred)))\n",
    "print(\"Precision score:  {:.3f}\".format(precision_score(Y_test,target_pred)))\n",
    "print(\"F1 score:         {:.3f}\".format(f1_score(Y_test,target_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a more systematic search for the ideal threshold, where we plot the three metrics with respect to the threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(Y_test, target_probas[:, 1]) \n",
    "F1 = 1/(0.5*(1/(recall+0.001)+1/(precision+0.001)))\n",
    "\n",
    "plt.title(\"Precision-Recall vs Threshold Chart\")\n",
    "plt.plot(thresholds, precision[:-1], \"b--\", label=\"Precision\")\n",
    "plt.plot(thresholds, recall[:-1], \"r--\", label=\"Recall\")\n",
    "plt.plot(thresholds, F1[:-1], \"k--\", label=\"F1\")\n",
    "plt.ylabel(\"Precision, Recall, F1\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As could be expected, when the threshold increases (harder/tougher quality test), precision increases but recall decreases.\n",
    "\n",
    "The better compromise (optimal F1) is obtained around threshold=0.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is sometimes interesting to quantify the **global** performance of a classifier model, over any choices of threshold, to assess its ability to solve different problems. This is the purpose of **ROC curve** and **AUC score**.\n",
    "\n",
    "The AUC is usually between 0.5 (bad score) and 1 (optimal score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_score = glm.decision_function(X_test)\n",
    "fpr, tpr, _ = roc_curve(Y_test, Y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"AUC is\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='exercise3'>Exercise 3 - Decision Tree</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a decision tree object and train it\n",
    "    \n",
    "In this exercise we are going to use the Decision Tree for regression, using the continuous variable 'Rolling_force_avg' as target.  \n",
    "    \n",
    "    DecisionTreeRegressor(): Defines model to be used, in this case: Regression Tree from tree class\n",
    "    max_depth: Parameter of a decision tree, defines how many levels with the tree have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our Train and Test data sets again.  \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    data_model.drop(['geometry_final', 'geometry_ok'], axis=1), # data set excl. target function\n",
    "    data_model['geometry_final'],                                          # target function\n",
    "    test_size=0.2,                                           # ratio of train and test sets\n",
    "    random_state=123                                         # setting up root for random split of data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Regression Tree model\n",
    "# Constrain the max_depth and the min_samples_leagf\n",
    "dt = DecisionTreeRegressor(max_depth=4, min_samples_leaf=5);\n",
    "dt.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the tree\n",
    "We'll use a packege called \"graphviz\" to draw the tree. Essentially, it's a special kind of graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the result object\n",
    "dot_data = StringIO()\n",
    "\n",
    "# This object will take the model (dt) and produce the elements necessary for the graph and put them in dot_data\n",
    "export_graphviz(dt, out_file=dot_data, filled=True, rounded=True, special_characters=True, feature_names=X_train.columns)\n",
    "\n",
    "#Create the graph frol dot_data\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "\n",
    "# Show the image\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions using the testing set\n",
    "    predict(): Applies trained model to new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the predictions using X_test\n",
    "tree_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model\n",
    "    mean_squared_error(actual value, predicted value):  Calculated MSE between actual and predicted value\n",
    "    r2_score(actual value, predicted value):            Calculates R2 between actual and predicted valu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show the evaluation results for Test, but also for Train for comparison\n",
    "print(\"METRICS FOR DECISION TREE\")\n",
    "print('Test Set Mean Sqared Error : ', mean_squared_error(Y_test, tree_pred))\n",
    "print('Test Set R2                : ', r2_score(Y_test, tree_pred))\n",
    "print('Train Set R2               : ', r2_score(Y_train, dt.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot prediction vs. actual\n",
    "Choose matplotlib or seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=Y_test, y=tree_pred, label='Predictions')\n",
    "sns.lineplot(x=Y_test, y=Y_test, color='gray', label='Perfect model')\n",
    "\n",
    "plt.axis('equal') # Make both axes scaled equally\n",
    "plt.xlabel('Real geometry_final [mm]')\n",
    "plt.ylabel('Predicted geometry_final [mm]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Plot residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using MatPlotLib\n",
    "sns.scatterplot(x=tree_pred, y=(Y_test - tree_pred), label='Prediction residuals')\n",
    "plt.axhline(0, color='gray', label='Perfect model') # adds reference line y = 0\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Rediduals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Bonus: Change the tree parameters\n",
    "Dicision tree parameters can be changed in DecisionTreeRegressor definition, i.e. min. number of samples for a leaf.\n",
    "Full breakdown of available options can be found here:   \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor\n",
    "\n",
    "Modify parameters of your choice and evaluate new model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reprint the current RMSE and R2 (for comparison later) for : (max_depth=4, min_samples_leaf= 5)\n",
    "print('Test Set Mean Sqared Error : ', mean_squared_error(Y_test, tree_pred))\n",
    "print('Test Set R2                : ', r2_score(Y_test, tree_pred))\n",
    "print('Train Set R2               : ', r2_score(Y_train, dt.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with changing the depth of the tree\n",
    "dt2 = DecisionTreeRegressor(max_depth=5);\n",
    "dt2.fit(X_train, Y_train);\n",
    "tree_pred2 = dt2.predict(X_test)\n",
    "\n",
    "print('Test Set Mean Sqared Error : ', mean_squared_error(Y_test, tree_pred2))\n",
    "print('Test Set R2                : ', r2_score(Y_test, tree_pred2))\n",
    "print('Train Set R2               : ', r2_score(Y_train, dt2.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='exercise4'>Exercise 4 - Random Forest</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge with a decision tree is overfitting, as seen from results of the previous exercice.  __Random Forest__ overcomes that by have a forest of trees which are randomly configured with different data.  \n",
    "\n",
    "We will use the same data as before, so again, we are using Random Forest for __Regression__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our Train and Test data sets again.  \n",
    "X_train, X_test, Y_train, ????? = train_test_split(\n",
    "    data_model.drop(['geometry_final', 'geometry_ok'], axis=1), # data set excl. target function\n",
    "    data_model['geometry_final'],                          # target function\n",
    "    test_size=0.2,                                           # ratio of train and test sets\n",
    "    random_state=123                                         # setting up root for random split of data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the random forest\n",
    "    RandomForestRegressor() : regression model using a random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "# train the model\n",
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict values of the response variable for new observations by the trained model using the other part of the data as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf.predict(?????)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check model accuracy\n",
    "    mean_squared_error()\n",
    "    r2_score()\n",
    "    mean_absolute_error\n",
    "We can use our wrapped function regression_validation for it as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"METRICS FOR RANDOM FOREST\")\n",
    "print('Test Set Mean Sqared Error : ', mean_squared_error(Y_test, rf_pred))\n",
    "print('Test Set R2                : ', r2_score(?????, rf_pred))\n",
    "print('Train Set R2               : ', r2_score(Y_train, rf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot prediction vs. actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=Y_test, y=rf_pred, label='Predictions')\n",
    "sns.lineplot(x=Y_test, y=Y_test, color='gray', label='Perfect model')\n",
    "\n",
    "plt.axis('equal') # Make both axes scaled equally\n",
    "plt.xlabel('Real geometry_final [mm]')\n",
    "plt.ylabel('Predicted geometry_final [mm]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understaning the model with variable importance\n",
    "\n",
    "With a normal decision tree, we can print out a graph of the rules used to make the regression.  That is not possible with Random Forest.  \n",
    "\n",
    "In its place, we can find out which variables (features) have the most influence. This is a bit complicated at first, so don't panic!\n",
    "\n",
    "    feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with two columns : Feature and Feature Importance\n",
    "# Sort the dataframe by Feature Importance in ascending order\n",
    "imp = pd.DataFrame({'Feature': X_train.columns,\n",
    "                    'Feature Importance': rf.feature_importances_}). \\\n",
    "        sort_values('Feature Importance', ascending=True)\n",
    "\n",
    "#Create a horizontal bar graph showing the features in their order of importance\n",
    "plt.barh(range(len(imp)), imp['Feature Importance'], color='b', align='center')\n",
    "plt.yticks(range(len(imp)), imp['Feature'])\n",
    "plt.xlabel('Relative Importance')\n",
    "\n",
    "# Before printing the bar graph, print theFeature Importance dataset\n",
    "imp.sort_values('Feature Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above information will be useful when discussing the results of the model with the process expert.  While we don't know the exact rules, at least we know which features are considered most important by this model! \n",
    "\n",
    "#### Understanding variable importance and influence with partial dependence plots\n",
    "\n",
    "A way to investigate how single input variables influence the target variable, we can use partial dependence plots. They do not exactly and quantitatively describe the relationship, but instead qualitatively how the model responds to changes in the input, keeping the rest of the variables fix. Let's analyze our Random Forest Model with this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "plot_partial_dependence(rf, \n",
    "                        X_train,\n",
    "                        features=range(X_train.shape[1]), \n",
    "                        feature_names=X_train.columns,\n",
    "                        grid_resolution=50,\n",
    "                        ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Tune the model adjusting its parameters\n",
    "    n_estimators: number of trees\n",
    "    max_features: # of variables\n",
    "    max_depth: maximum depth of the three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200, \n",
    "    max_features=4, \n",
    "    max_depth=7)\n",
    "\n",
    "rf.fit(X_train, Y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"METRICS FOR RANDOM FOREST\")\n",
    "print('Test Set Mean Sqared Error : ', mean_squared_error(Y_test, rf_pred))\n",
    "print('Test Set R2                : ', r2_score(Y_test, rf_pred))\n",
    "print('Train Set R2               : ', r2_score(Y_train, rf.predict(X_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: alternative with GradientBoosting and study of partial dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth=5, learning_rate=0.03, min_samples_leaf=1, \n",
    "                                n_estimators=200, subsample=0.4, loss='lad')\n",
    "gbr.???(X_train, Y_train)\n",
    "gbr_pred = gbr.predict(X_test)\n",
    "print(\"METRICS FOR GRADIENT BOOSTING\")\n",
    "print('Test Set Mean Sqared Error : ', mean_squared_error(Y_test, gbr_pred))\n",
    "print('Test Set R2                : ', r2_score(Y_test, gbr_pred))\n",
    "print('Train Set R2               : ', r2_score(Y_train, gbr.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "plot_partial_dependence(gbr, \n",
    "                        X_train,\n",
    "                        features=range(X_train.shape[1]), \n",
    "                        feature_names=X_train.columns,\n",
    "                        grid_resolution=50,\n",
    "                        ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: alternative with GradientBoosting and study of partial dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth=5, learning_rate=0.03, min_samples_leaf=1, \n",
    "                                n_estimators=200, subsample=0.4, loss='lad')\n",
    "gbr.???(X_train, Y_train)\n",
    "gbr_pred = gbr.predict(X_test)\n",
    "print(\"METRICS FOR GRADIENT BOOSTING\")\n",
    "print('Test Set Mean Sqared Error : ', mean_squared_error(Y_test, gbr_pred))\n",
    "print('Test Set R2                : ', r2_score(Y_test, gbr_pred))\n",
    "print('Train Set R2               : ', r2_score(Y_train, gbr.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sklearn.inspection.plot_partial_dependence for more recent versions of sklearn\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "plot_partial_dependence(gbr, \n",
    "                        X_train,\n",
    "                        features=range(X_train.shape[1]), \n",
    "                        feature_names=X_train.columns,\n",
    "                        grid_resolution=50,\n",
    "                        ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Simplifying model on subset of data\n",
    "\n",
    "For a fairly complex model, it seems like three variables in particular are important.\n",
    "\n",
    "We've also seen in previous plots that the data differs quite a bit between different recipes. Insterad of trying to make a model for any case, it might make sense to make a model for one stable production state (=recipe)\n",
    "\n",
    "Below, it looks like the latest production with Recipe-C is fairly homogenous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=data, x='geometry_final', y='glass_temp_zone1', hue='recipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose only the rows where the recipe columns says Recipe-C\n",
    "data_regr = data[data['recipe'] ??? 'Recipe-C'].copy()\n",
    "\n",
    "regr_features = ['glass_temp_zone1', 'pressing_pressure', 'pressing_time', 'geometry_final']\n",
    "data_regr = data_regr[regr_features]\n",
    "data_regr = data_regr.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    data_regr.drop('geometry_final', axis=1),  # data set excl. target function\n",
    "    data_regr['geometry_final'],               # target function\n",
    "    test_size=0.2,                                # ratio of train and test sets\n",
    "    random_state=123                              # setting up root for random split of data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression()       # Create the lR model called regr\n",
    "regr.fit(X_train, Y_train);     # Train the model on the train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=Y_test, y=regr_pred, label='Predictions')\n",
    "sns.lineplot(x=Y_test, y=Y_test, color='gray', label='Perfect model')\n",
    "\n",
    "plt.axis('equal') # Make both axes scaled equally\n",
    "plt.xlabel('Real geometry_final [mm]')\n",
    "plt.ylabel('Predicted geometry_final [mm]')\n",
    "\n",
    "print(\"METRICS FOR LINEAR REGRESSION\")\n",
    "print('Test Set Mean Sqared Error : ', mean_squared_error(Y_test, regr_pred))\n",
    "print('Test Set R2                : ', r2_score(Y_test, regr_pred))\n",
    "print('Train Set R2               : ', r2_score(Y_train, regr.predict(X_train)))\n",
    "\n",
    "print(f'\\nIntercept: \\t{regr.intercept_:.3f}')\n",
    "for f, c in zip(regr_features, regr.coef_):\n",
    "    print(f'{f}: {c:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the latest data with Recipe-C, we could build a successfull simple linear model with good performance!\n",
    "\n",
    "What we might have lost on accuracy and trying to model every process, we win in simplicity and intuition.\n",
    "\n",
    "**For example, this model predicts that for an increase of 1 degree C in 'glass_temp_zone1' will lead to an 0.64 mm increase in 'geometry_final'.**\n",
    "\n",
    "This can then be easily applied in different ways without using a black box model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='exercise5'>Exercise 5 - K-means Clustering</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercice we aim at clustering data points, which is a task for unsupervised machine learning. \n",
    "As a consequence, there is no need for spliting the data into train and test sets and the whole dataset will be use to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_cluster = data_model[['geometry_final', 'glass_temp_zone1']].copy()\n",
    "\n",
    "sns.scatterplot(data=data_cluster, x='geometry_final', y='glass_temp_zone1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Clusters for n=3\n",
    "    KMeans(n_clusters=n): Defines model: k-means clustering with n clusters; and trains it using data\n",
    "    fit(X): Trains defined model using data in table X\n",
    "    \n",
    "    Learn more here :   \n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Kmeans model and train it\n",
    "# We're not really training it.  We are just giving it the data that it will use.  \n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(data_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions using the testing set\n",
    "    predict(): Applies trained model to new data to get predicted cluster allocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the clusters\n",
    "y_kmeans = kmeans.predict(data_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate centroids of clusters\n",
    "    kmeans.cluster_centers_: Returns list of central points for the trained clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the centers from the model and print them\n",
    "centers = kmeans.cluster_centers_\n",
    "print(centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot cluster centroids and predicted clusters\n",
    "Let's compose the chart drawing two scatter plots on one plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create a first chart which are the data points, with colors showing the 3 clusters defined in y_kmeans3\n",
    "sns.scatterplot(data=data_cluster, x='geometry_final', y='glass_temp_zone1', hue=y_kmeans)\n",
    "#Create a second chart that shows the centroids in red\n",
    "plt.scatter(centers[:,0], centers[:,1], color='r')\n",
    "#plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that the clusters form pretty horizontal lines.** This is because the scale and variability of 'glass_temp_zone1' is bigger than that of 'geometry_final' => the distance in this dimension is bigger. \n",
    "\n",
    "(We can visualize this by uncommenting the line **#plt.axis('equal')** in the cell above.)\n",
    "\n",
    "Let's try **normalizing** the data to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the data to make a normalized set\n",
    "data_cluster_norm = data_cluster.copy()\n",
    "\n",
    "# Calculate and subtract the mean from all values column-wise\n",
    "data_cluster_norm = data_cluster_norm - data_cluster_norm.mean()\n",
    "\n",
    "# Calculate and divide by the standard deviation for all values column-wise\n",
    "data_cluster_norm = data_cluster_norm / data_cluster_norm.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(data_cluster_norm)\n",
    "\n",
    "y_kmeans = kmeans.predict(data_cluster_norm)\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "sns.scatterplot(data=data_cluster_norm, x='geometry_final', y='glass_temp_zone1', hue=y_kmeans)\n",
    "plt.scatter(centers[:,0], centers[:,1], color='r')\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reference, let's see how the data was grouped after recipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=data, x='geometry_final', y='glass_temp_zone1', hue='recipe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to change the number of clusters from 3 to something else! What do we see?\n",
    "\n",
    "#### Although we're only visualizing the clustering in two dimension, we can give the clustering model many dimension, for example the same data that we used for the previous models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same variable selection as for the previous exercises\n",
    "data_cluster_all = data_model.copy()\n",
    "\n",
    "# Normalize the variables (here we subtract the mean and divide by the standard deviation in one line!)\n",
    "data_cluster_all = (data_cluster_all - data_cluster_all.mean()) / data_cluster_all.std()\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(data_cluster_all)\n",
    "\n",
    "y_kmeans = kmeans.predict(data_cluster_all)\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "sns.scatterplot(data=data_cluster_all, x='geometry_final', y='glass_temp_zone1', hue=y_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate inertia\n",
    "    kmeans.inertia_: Measure of how internally coherent are the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Inertia: ', kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which number of clusters resulted in better classification (inertia was lower)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Finding the optimum number of clusters: The Elbow method\n",
    "\n",
    "How many clusters gives the best answer?  One technique is to test out several values and plot them on a curve.  The curve will have an elbow and that will indicate the best number of clusters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through a range of cluster values\n",
    "# For each value, find the cluster centers and calculate the inertia\n",
    "\n",
    "Sum_of_squared_distances = []\n",
    "K = range(1,15)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k, random_state=0)\n",
    "    km = km.fit(data_cluster_norm)\n",
    "    Sum_of_squared_distances.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a graph with x= Cluster count and Y = Inertia\n",
    "\n",
    "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which number of clusters would you choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='bonus'>Bonus - Selecting Variables based on Importance</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of variables from features importance\n",
    "\n",
    "At the very start, we loaded our dataset and then selected only a subset of the variables to be used to predict Rolling_force_avg.\n",
    "\n",
    "A more methodical way is to actually run a quick linear regression with penalization (Ridge model) to see which are the most influential variables and then focus on those.  \n",
    "\n",
    "In this exercise, we'll see how that is done.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the train-test split with all numeric variables\n",
    "cols = data_model.select_dtypes(include=float).columns\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    data_model[cols].drop('geometry_final', axis=1), # data set excl. target function\n",
    "    data_model['geometry_final'],                       # target function\n",
    "    test_size=0.2,                                      # ratio of train and test sets\n",
    "    random_state=123                                    # setting up root for random split of data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at performance for dummy regressor\n",
    "dummy = DummyRegressor();\n",
    "dummy.fit(X_train, Y_train);\n",
    "Y_pred = dummy.predict(X_test)\n",
    "print(mean_squared_error(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for a good regularization parameter alpha for the Ridge model \n",
    "for a in np.logspace(-4, -1, num=10):\n",
    "    regr = Ridge(alpha=a, normalize=True)\n",
    "    regr.fit(X_train, Y_train)\n",
    "    Y_pred = regr.predict(X_test)\n",
    "    print(\"alpha:\", np.round(a, 4), \"MSE:\", np.round(mean_squared_error(Y_test, Y_pred), 3),\n",
    "          \"R2:\", np.round(r2_score(Y_test, Y_pred), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the Ridge model\n",
    "regr = Ridge(alpha=0.01, normalize=True)\n",
    "regr.fit(X_train, Y_train)\n",
    "Y_pred = regr.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(Y_test, Y_pred))\n",
    "print(\"R2:\", r2_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# look at coefficients' importance, given by the product of \n",
    "# - the coefficient value\n",
    "# - the std of the associated variable\n",
    "# for more details, see:\n",
    "# https://scikit-learn.org/stable/auto_examples/inspection/plot_linear_model_coefficient_interpretation.html\n",
    "\n",
    "coefs = pd.DataFrame(regr.coef_ * X_train.std(axis=0),\n",
    "                     columns=['Coefficient importance'], \n",
    "                     index=data_model[cols].drop('geometry_final', axis=1).columns)\n",
    "coefs.plot(kind='barh', figsize=(9, 7))\n",
    "plt.title('Ridge model, small regularization')\n",
    "plt.axvline(x=0, color='.5')\n",
    "plt.subplots_adjust(left=.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
